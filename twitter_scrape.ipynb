{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369a615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "from emoji import UNICODE_EMOJI # Read documentation\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd404a",
   "metadata": {},
   "source": [
    "**Defining tickers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e652b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2e144",
   "metadata": {},
   "source": [
    "**Twitter scraping example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d06d7e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ðŸ¥‡', 'ðŸ¥ˆ', 'ðŸ¥‰', 'â†—']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tweets = 100\n",
    "all_tweets = []\n",
    "all_emojis = []\n",
    "\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(ticker).get_items()):\n",
    "    if i > max_tweets:\n",
    "        break\n",
    "    all_tweets.append(tweet.content)\n",
    "\n",
    "for i in all_tweets:\n",
    "    for element in i:\n",
    "        if element in UNICODE_EMOJI['en']:\n",
    "            all_emojis.append(element)\n",
    "\n",
    "all_emojis[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3e0d9",
   "metadata": {},
   "source": [
    "**Firstly, scraping for emoji category data from the web:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c062dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://character.construction/emoji-categories\"\n",
    "response = requests.get(url)\n",
    "html_parsed = bs4.BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edfeec",
   "metadata": {},
   "source": [
    "**Classifying into headers (categories) and tables (individual emojis in these categories)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e413bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = html_parsed.find_all(\"table\")\n",
    "headers = html_parsed.find_all(\"h3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bee058",
   "metadata": {},
   "source": [
    "**Cleaning header strings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae181a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_headers = []\n",
    "\n",
    "for i in headers:\n",
    "    cleaned = str(i).replace(\"<h3 id=\",\"\").replace(\"</h3>\",\"\")\n",
    "    cleaned = cleaned[(cleaned.find(\">\")+1):]\n",
    "    clean_headers.append(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eedfcde",
   "metadata": {},
   "source": [
    "**Cleaning tables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0830012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from StackExchange to find nth occurence of a substring:\n",
    "\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f11386",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tables = []\n",
    "\n",
    "for i in tables:\n",
    "    all = str(i.find_all(\"td\"))\n",
    "    number_unicodes = all.count(\"U+\")\n",
    "    unicode_list = []\n",
    "    for i in range(0,(number_unicodes+1)):\n",
    "        x = find_nth(all, \"U+\", i)\n",
    "        unicode_char = all[x:(x+7)]\n",
    "        # Converting into a symbol:\n",
    "        try:\n",
    "            unicode_symbol = chr(int(unicode_char[2:], 16))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        unicode_list.append(unicode_symbol)\n",
    "    clean_tables.append(unicode_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6d89f",
   "metadata": {},
   "source": [
    "**Creating a dictionary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fdb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = {}\n",
    "for i in range(0,98):\n",
    "    classification[str(clean_headers[i])] = clean_tables[i]\n",
    "\n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7302516",
   "metadata": {},
   "source": [
    "**Assigning scores to different emoji classes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7e8a000",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'in <string>' requires string as left operand, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\GitHub\\Introduction-to-Programming\\twitter_scrape.ipynb Cell 18'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/GitHub/Introduction-to-Programming/twitter_scrape.ipynb#ch0000016?line=0'>1</a>\u001b[0m sentiment \u001b[39m=\u001b[39m {}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/GitHub/Introduction-to-Programming/twitter_scrape.ipynb#ch0000016?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m classification:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/GitHub/Introduction-to-Programming/twitter_scrape.ipynb#ch0000016?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m [\u001b[39m\"\u001b[39;49m\u001b[39mSmil\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mAffection\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39min\u001b[39;49;00m key:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/GitHub/Introduction-to-Programming/twitter_scrape.ipynb#ch0000016?line=3'>4</a>\u001b[0m         sentiment[key] \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/GitHub/Introduction-to-Programming/twitter_scrape.ipynb#ch0000016?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNeg\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m key:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'in <string>' requires string as left operand, not list"
     ]
    }
   ],
   "source": [
    "sentiment = {}\n",
    "for key in classification:\n",
    "    if [\"Smil\", \"Affection\"] in key:\n",
    "        sentiment[key] = 0.5\n",
    "    if \"Neg\" in key:\n",
    "        sentiment[key] = -1.0\n",
    "    if \"skeptic\" in key:\n",
    "        sentiment[key] = -0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65c4f19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Face, Smiling', 'Face, Affection', 'Face, Tongue', 'Face, Hand', 'Face, Neutral-skeptical', 'Face, Sleepy', 'Face, Unwell', 'Face, Hat', 'Face, Glasses', 'Face, Concerned', 'Face, Negative', 'Face, Costume', 'Cat, Face', 'Monkey, Face', 'Emotion', 'Hand, Fingers-open', 'Hand, Fingers-partial', 'Hand, Single-finger', 'Hand, Fingers-closed', 'Hands', 'Hand, Prop', 'Body, Parts', 'Person', 'Person, Gesture', 'Person, Role', 'Person, Fantasy', 'Person, Activity', 'Person, Sport', 'Person, Resting', 'Family', 'Person, Symbol', 'Skin, Tone', 'Hair, Style', 'Animal, Mammal', 'Animal, Bird', 'Animal, Amphibian', 'Animal, Reptile', 'Animal, Marine', 'Animal, Bug', 'Plant, Flower', 'Plant, Other', 'Food, Fruit', 'Food, Vegetable', 'Food, Prepared', 'Food, Asian', 'Food, Marine', 'Food, Sweet', 'Drink', 'Dishware', 'Place, Map', 'Place, Geographic', 'Place, Building', 'Place, Religious', 'Place, Other', 'Transport, Ground', 'Transport, Water', 'Transport, Air', 'Hotel', 'Time', 'Sky &amp; weather', 'Event', 'Award, Medal', 'Sport', 'Game', 'Arts &amp; crafts', 'Clothing', 'Sound', 'Music', 'Musical, Instrument', 'Phone', 'Computer', 'Light &amp; video', 'Book, Paper', 'Money', 'Mail', 'Writing', 'Office', 'Lock', 'Tool', 'Science', 'Medical', 'Household', 'Other, Object', 'Transport, Sign', 'Warning', 'Arrow', 'Religion', 'Zodiac', 'Av, Symbol', 'Gender', 'Math', 'Punctuation', 'Currency', 'Other, Symbol', 'Keycap', 'Alphanum', 'Geometric', 'Flag'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
