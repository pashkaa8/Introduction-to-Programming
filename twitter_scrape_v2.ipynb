{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "from emoji import UNICODE_EMOJI # Read documentation\n",
    "import requests\n",
    "import bs4\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd404a",
   "metadata": {},
   "source": [
    "**Defining example ticker to work with**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e652b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2e144",
   "metadata": {},
   "source": [
    "**Twitter scraping example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d06d7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_scrape(ticker, max_tweets):\n",
    "    all_tweets = []\n",
    "    all_emojis = []\n",
    "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(ticker).get_items()):\n",
    "        if i > max_tweets:\n",
    "            break\n",
    "        all_tweets.append(tweet.content)\n",
    "\n",
    "    for i in all_tweets:\n",
    "        for element in i:\n",
    "            if element in UNICODE_EMOJI['en']:\n",
    "                all_emojis.append(element)\n",
    "\n",
    "    return (all_emojis, all_tweets)\n",
    "\n",
    "all_emojis = twitter_scrape(ticker, 100)[0]\n",
    "all_tweets = twitter_scrape(ticker, 100)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b376c",
   "metadata": {},
   "source": [
    "**Obtaining S&P 500 tickers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28aa2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "first_table = wikipedia[0]\n",
    "tickers = first_table[\"Symbol\"]\n",
    "sp_tickers = [i for i in tickers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3e0d9",
   "metadata": {},
   "source": [
    "**Scraping for emoji category data from the web:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c062dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://kt.ijs.si/data/Emoji_sentiment_ranking/\"\n",
    "response = requests.get(url)\n",
    "html_parsed = bs4.BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edfeec",
   "metadata": {},
   "source": [
    "**Classifying the main table into sub-tables with individual emojis (TRs):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e413bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = html_parsed.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27ac0b",
   "metadata": {},
   "source": [
    "**Scraping emoji symbols:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f14791",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_list = []\n",
    "\n",
    "for row in tables:\n",
    "    string_row = str(row)\n",
    "    emoji = string_row[(string_row.find(\"<tr><td>\")+8):(string_row.find(\"<tr><td>\")+9)]\n",
    "    emoji_list.append(emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd278f53",
   "metadata": {},
   "source": [
    "**Scraping sentiment scores:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94fce237",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = []\n",
    "\n",
    "for row in tables:\n",
    "    string_row = str(row)\n",
    "    if string_row[string_row.find(\"sentiment score: \")+17] == \"-\":\n",
    "        score = string_row[(string_row.find(\"sentiment score: \")+17):(string_row.find(\"sentiment score: \")+23)]\n",
    "    else:\n",
    "        score = string_row[(string_row.find(\"sentiment score: \")+17):(string_row.find(\"sentiment score: \")+22)]\n",
    "    sentiment_scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6d89f",
   "metadata": {},
   "source": [
    "**Creating a dictionary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01fdb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {}\n",
    "for i in range(1,752):\n",
    "    score_dict[emoji_list[i]] = sentiment_scores[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb50d1",
   "metadata": {},
   "source": [
    "**Calculating sentiment scores from actual tweets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sentiment score for AAPL is 22.7\n"
     ]
    }
   ],
   "source": [
    "def emoji_score(all_emojis):\n",
    "    total_score = 0\n",
    "    for emoji in all_emojis:\n",
    "        if emoji in score_dict.keys():\n",
    "            total_score = total_score + float(score_dict[emoji])\n",
    "    return round(total_score,2)\n",
    "\n",
    "emoji_score1 = emoji_score(all_emojis)\n",
    "print(\"Current sentiment score for\", ticker, \"is\", round(emoji_score1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4146756",
   "metadata": {},
   "source": [
    "**Starting with text analysis using NLTK:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751dee4a",
   "metadata": {},
   "source": [
    "Source: https://realpython.com/python-nltk-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960805d",
   "metadata": {},
   "source": [
    "**Importing stop-words, such as \"and\", \"or\" and \"but\" to filter them out:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a31dbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62df09",
   "metadata": {},
   "source": [
    "**Creating tokenized lists of tweet words:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc10df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_list = []\n",
    "for x in all_tweets:\n",
    "    split_tweet = x.split()\n",
    "    for word in split_tweet:\n",
    "        if word.isalpha():\n",
    "            if word.lower() not in stopwords:\n",
    "                tokenized_list.append(word.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b0384c",
   "metadata": {},
   "source": [
    "**Looking at the most frequent words:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ea541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   公開記念   apple      de  market   stock trading   today opening    last reports \n",
      "     15      15      10       9       8       7       7       6       6       6 \n"
     ]
    }
   ],
   "source": [
    "x = nltk.FreqDist(tokenized_list)\n",
    "x.tabulate(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ee2bb",
   "metadata": {},
   "source": [
    "**Looking at the most frequent three-word collocations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e270ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('reports', 'today', 'markets'), 5),\n",
       " (('octane', 'predicting', 'gain'), 4),\n",
       " (('predicting', 'gain', 'opening'), 4),\n",
       " (('gain', 'opening', 'price'), 4),\n",
       " (('opening', 'price', 'tuesday'), 4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nltk.collocations.TrigramCollocationFinder.from_words(tokenized_list)\n",
    "y.ngram_fd.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa070582",
   "metadata": {},
   "source": [
    "**Performing sentiment analysis using VADER library:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dacae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754ee12",
   "metadata": {},
   "source": [
    "**Counting the number of positive, negative and neutral tweets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51eaf612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_score(all_tweets):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    neutral = 0\n",
    "    for x in all_tweets:\n",
    "        tweet_score = sent.polarity_scores(x)\n",
    "        if tweet_score[\"compound\"] >= 0.3:\n",
    "            positive += 1\n",
    "        elif tweet_score[\"compound\"] > -0.3:\n",
    "            neutral += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "    return [positive, neutral, negative]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887110b0",
   "metadata": {},
   "source": [
    "**Providing a summary of the sentiment, that is, emoji score + number of positive/negative/neutral tweets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91107e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.7 [32, 60, 9]\n"
     ]
    }
   ],
   "source": [
    "emoji_score2 = emoji_score(all_emojis)\n",
    "text_score2 = text_score(all_tweets)\n",
    "\n",
    "print(emoji_score2, text_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63312de1",
   "metadata": {},
   "source": [
    "**Providing a summary of these scores for selected tickers:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff7ed5",
   "metadata": {},
   "source": [
    "Explain here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8bf75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ticker_scores = pd.DataFrame()\n",
    "input_ticker = \"\"\n",
    "input_ticker_list = []\n",
    "\n",
    "while input_ticker != \"Stop\":  \n",
    "    input_ticker = str(input(\"Please enter some tickers or type 'Stop': \"))\n",
    "    if input_ticker != \"Stop\":\n",
    "        input_ticker_list.append(input_ticker)\n",
    "\n",
    "for ticker in input_ticker_list:\n",
    "    data = twitter_scrape(ticker, 100)\n",
    "    emojis = data[0]\n",
    "    tweets = data[1]\n",
    "    selected_ticker_scores.loc[ticker, \"Ticker\"] = ticker\n",
    "    selected_ticker_scores.loc[ticker, \"Emoji Score\"] = emoji_score(emojis)\n",
    "    selected_ticker_scores.loc[ticker, \"Positive\"] = text_score(tweets)[0]\n",
    "    selected_ticker_scores.loc[ticker, \"Neutral\"] = text_score(tweets)[1]\n",
    "    selected_ticker_scores.loc[ticker, \"Negative\"] = text_score(tweets)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f07889b",
   "metadata": {},
   "source": [
    "**Sorting by the highest Emoji Scores, as an example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f43a34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Emoji Score</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GOGL</th>\n",
       "      <td>GOGL</td>\n",
       "      <td>18.56</td>\n",
       "      <td>16.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>10.76</td>\n",
       "      <td>19.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>FB</td>\n",
       "      <td>6.65</td>\n",
       "      <td>13.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>3.39</td>\n",
       "      <td>25.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker  Emoji Score  Positive  Neutral  Negative\n",
       "GOGL   GOGL        18.56      16.0     79.0       6.0\n",
       "AMZN   AMZN        10.76      19.0     78.0       4.0\n",
       "FB       FB         6.65      13.0     84.0       4.0\n",
       "TSLA   TSLA         3.39      25.0     65.0      11.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ticker_scores.sort_values(by=[\"Emoji Score\"], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
