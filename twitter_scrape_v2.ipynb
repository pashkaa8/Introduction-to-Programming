{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "from emoji import UNICODE_EMOJI # Read documentation\n",
    "import requests\n",
    "import bs4\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd404a",
   "metadata": {},
   "source": [
    "**Defining tickers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e652b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2e144",
   "metadata": {},
   "source": [
    "**Twitter scraping example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d06d7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_scrape(ticker, max_tweets):\n",
    "    all_tweets = []\n",
    "    all_emojis = []\n",
    "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(ticker).get_items()):\n",
    "        if i > max_tweets:\n",
    "            break\n",
    "        all_tweets.append(tweet.content)\n",
    "\n",
    "    for i in all_tweets:\n",
    "        for element in i:\n",
    "            if element in UNICODE_EMOJI['en']:\n",
    "                all_emojis.append(element)\n",
    "\n",
    "    return (all_emojis, all_tweets)\n",
    "\n",
    "all_emojis = twitter_scrape(ticker, 100)[0]\n",
    "all_tweets = twitter_scrape(ticker, 100)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b376c",
   "metadata": {},
   "source": [
    "**Obtaining S&P 500 tickers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28aa2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "first_table = wikipedia[0]\n",
    "tickers = first_table[\"Symbol\"]\n",
    "sp_tickers = [i for i in tickers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3e0d9",
   "metadata": {},
   "source": [
    "**Scraping for emoji category data from the web:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c062dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://kt.ijs.si/data/Emoji_sentiment_ranking/\"\n",
    "response = requests.get(url)\n",
    "html_parsed = bs4.BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edfeec",
   "metadata": {},
   "source": [
    "**Classifying the main table into sub-tables with individual emojis (TRs):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e413bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = html_parsed.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27ac0b",
   "metadata": {},
   "source": [
    "**Scraping emoji symbols:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07f14791",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_list = []\n",
    "\n",
    "for row in tables:\n",
    "    string_row = str(row)\n",
    "    emoji = string_row[(string_row.find(\"<tr><td>\")+8):(string_row.find(\"<tr><td>\")+9)]\n",
    "    emoji_list.append(emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd278f53",
   "metadata": {},
   "source": [
    "**Scraping sentiment scores:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94fce237",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = []\n",
    "\n",
    "for row in tables:\n",
    "    string_row = str(row)\n",
    "    if string_row[string_row.find(\"sentiment score: \")+17] == \"-\":\n",
    "        score = string_row[(string_row.find(\"sentiment score: \")+17):(string_row.find(\"sentiment score: \")+23)]\n",
    "    else:\n",
    "        score = string_row[(string_row.find(\"sentiment score: \")+17):(string_row.find(\"sentiment score: \")+22)]\n",
    "    sentiment_scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6d89f",
   "metadata": {},
   "source": [
    "**Creating a dictionary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "01fdb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {}\n",
    "for i in range(1,752):\n",
    "    score_dict[emoji_list[i]] = sentiment_scores[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb50d1",
   "metadata": {},
   "source": [
    "**Calculating sentiment scores from actual tweets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sentiment score for ZTS is 14.81\n"
     ]
    }
   ],
   "source": [
    "def emoji_score(all_emojis):\n",
    "    total_score = 0\n",
    "    for emoji in all_emojis:\n",
    "        if emoji in score_dict.keys():\n",
    "            total_score = total_score + float(score_dict[emoji])\n",
    "    return round(total_score,2)\n",
    "\n",
    "emoji_score1 = emoji_score(all_emojis)\n",
    "print(\"Current sentiment score for\", ticker, \"is\", round(emoji_score1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4146756",
   "metadata": {},
   "source": [
    "**Starting with text analysis using NLTK:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751dee4a",
   "metadata": {},
   "source": [
    "Source: https://realpython.com/python-nltk-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960805d",
   "metadata": {},
   "source": [
    "**Importing stop-words, such as \"and\", \"or\" and \"but\" to filter them out:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62df09",
   "metadata": {},
   "source": [
    "**Creating tokenized lists of tweet words:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6bc10df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_list = []\n",
    "for x in all_tweets:\n",
    "    split_tweet = x.split()\n",
    "    for word in split_tweet:\n",
    "        if word.isalpha():\n",
    "            if word.lower() not in stopwords:\n",
    "                tokenized_list.append(word.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b0384c",
   "metadata": {},
   "source": [
    "**Looking at the most frequent words:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nltk.FreqDist(tokenized_list)\n",
    "x.tabulate(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ee2bb",
   "metadata": {},
   "source": [
    "**Looking at the most frequent three-word collocations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e270ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nltk.collocations.TrigramCollocationFinder.from_words(tokenized_list)\n",
    "y.ngram_fd.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa070582",
   "metadata": {},
   "source": [
    "**Performing sentiment analysis using VADER library:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6dacae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754ee12",
   "metadata": {},
   "source": [
    "**Counting the number of positive, negative and neutral tweets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51eaf612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_score(all_tweets):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    neutral = 0\n",
    "    for x in all_tweets:\n",
    "        tweet_score = sent.polarity_scores(x)\n",
    "        if tweet_score[\"compound\"] >= 0.3:\n",
    "            positive += 1\n",
    "        elif tweet_score[\"compound\"] > -0.3:\n",
    "            neutral += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "    return [positive, neutral, negative]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887110b0",
   "metadata": {},
   "source": [
    "**Providing a summary of the sentiment, that is, emoji score + number of positive/negative/neutral tweets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "91107e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.809 [17, 76, 8]\n"
     ]
    }
   ],
   "source": [
    "emoji_score2 = emoji_score(all_emojis)\n",
    "text_score2 = text_score(all_tweets)\n",
    "\n",
    "print(emoji_score2, text_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63312de1",
   "metadata": {},
   "source": [
    "**Providing a summary of these scores for all S&P 500 tickers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_scores = pd.DataFrame()\n",
    "\n",
    "for ticker in sp_tickers:\n",
    "    data = twitter_scrape(ticker, 10)\n",
    "    emojis = data[0]\n",
    "    tweets = data[1]\n",
    "    sp500_scores.loc[ticker, \"Ticker\"] = ticker\n",
    "    sp500_scores.loc[ticker, \"Emoji Score\"] = emoji_score(emojis)\n",
    "    sp500_scores.loc[ticker, \"Positive\"] = text_score(tweets)[0]\n",
    "    sp500_scores.loc[ticker, \"Neutral\"] = text_score(tweets)[1]\n",
    "    sp500_scores.loc[ticker, \"Negative\"] = text_score(tweets)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f07889b",
   "metadata": {},
   "source": [
    "**Sorting by the highest Emoji Scores, as an example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9f43a34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Emoji Score</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TFC</th>\n",
       "      <td>TFC</td>\n",
       "      <td>20.792</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDOS</th>\n",
       "      <td>LDOS</td>\n",
       "      <td>15.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCA</th>\n",
       "      <td>HCA</td>\n",
       "      <td>14.135</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIVB</th>\n",
       "      <td>SIVB</td>\n",
       "      <td>11.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>T</td>\n",
       "      <td>11.077</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETN</th>\n",
       "      <td>ETN</td>\n",
       "      <td>-0.603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT</th>\n",
       "      <td>CAT</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOW</th>\n",
       "      <td>NOW</td>\n",
       "      <td>-1.126</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANET</th>\n",
       "      <td>ANET</td>\n",
       "      <td>-1.649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMD</th>\n",
       "      <td>RMD</td>\n",
       "      <td>-12.502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker  Emoji Score  Positive  Neutral  Negative\n",
       "TFC     TFC       20.792       2.0      9.0       0.0\n",
       "LDOS   LDOS       15.600       0.0      8.0       3.0\n",
       "HCA     HCA       14.135       4.0      6.0       1.0\n",
       "SIVB   SIVB       11.250       1.0     10.0       0.0\n",
       "T         T       11.077       4.0      6.0       1.0\n",
       "...     ...          ...       ...      ...       ...\n",
       "ETN     ETN       -0.603       1.0      8.0       2.0\n",
       "CAT     CAT       -0.773       2.0      8.0       1.0\n",
       "NOW     NOW       -1.126       8.0      2.0       1.0\n",
       "ANET   ANET       -1.649       1.0      9.0       1.0\n",
       "RMD     RMD      -12.502       0.0     11.0       0.0\n",
       "\n",
       "[504 rows x 5 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_scores.sort_values(by=[\"Emoji Score\"], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
